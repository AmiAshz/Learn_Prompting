"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[5641],{3905:(e,a,t)=>{t.d(a,{Zo:()=>m,kt:()=>f});var o=t(67294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);a&&(o=o.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,o)}return t}function s(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,o,n=function(e,a){if(null==e)return{};var t,o,n={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var l=o.createContext({}),p=function(e){var a=o.useContext(l),t=a;return e&&(t="function"==typeof e?e(a):s(s({},a),e)),t},m=function(e){var a=p(e.components);return o.createElement(l.Provider,{value:a},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var a=e.children;return o.createElement(o.Fragment,{},a)}},d=o.forwardRef((function(e,a){var t=e.components,n=e.mdxType,r=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),c=p(t),d=n,f=c["".concat(l,".").concat(d)]||c[d]||u[d]||r;return t?o.createElement(f,s(s({ref:a},m),{},{components:t})):o.createElement(f,s({ref:a},m))}));function f(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var r=t.length,s=new Array(r);s[0]=d;var i={};for(var l in a)hasOwnProperty.call(a,l)&&(i[l]=a[l]);i.originalType=e,i[c]="string"==typeof e?e:n,s[1]=i;for(var p=2;p<r;p++)s[p]=t[p];return o.createElement.apply(null,s)}return o.createElement.apply(null,t)}d.displayName="MDXCreateElement"},41030:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>g,contentTitle:()=>d,default:()=>h,frontMatter:()=>u,metadata:()=>f,toc:()=>k});var o=t(87462),n=(t(67294),t(3905));const r=t.p+"assets/images/mrkl_task-12b7d810cd15b51db59158e42fc156bf.png",s=t.p+"assets/images/dataset-795d02eccc193dc46031731fa8a0e5be.png",i=t.p+"assets/images/load_dataset-df696753aa1a25a052522f4db16fcaf6.png",l=t.p+"assets/images/model-d000ffaa21da2ad7da6811d42f7bba85.png",p=t.p+"assets/images/extract-dc8227e6121f666e40788126c3f24fb3.png",m=t.p+"assets/images/search-747fcaa244074c8743c305a58950233e.png",c=t.p+"assets/images/final-6ff03aff4efdfb2215cd1aad24f37ced.png",u={sidebar_position:2},d="\ud83d\udfe1 Usando Ferramentas de LLM",f={unversionedId:"advanced_applications/mrkl",id:"advanced_applications/mrkl",title:"\ud83d\udfe1 Usando Ferramentas de LLM",description:"Os sistemas MRKL (@karpas2022mrkl) (Racioc\xednio Modular, Conhecimento e Linguagem, ou Modular Reasoning, Knowledge and Language, em ingl\xeas) s\xe3o uma arquitetura neuro-simb\xf3lica que combinam LLMs (computa\xe7\xe3o neural) e ferramentas externas como calculadoras (computa\xe7\xe3o simb\xf3lica) para resolver problemas complexos.",source:"@site/i18n/pt/docusaurus-plugin-content-docs/current/advanced_applications/mrkl.md",sourceDirName:"advanced_applications",slug:"/advanced_applications/mrkl",permalink:"/pt/docs/advanced_applications/mrkl",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/advanced_applications/mrkl.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/pt/docs/advanced_applications/overview"},next:{title:"\ud83d\udfe1 LLMs que Raciocinam e Reagem",permalink:"/pt/docs/advanced_applications/react"}},g={},k=[{value:"Um Exemplo",id:"um-exemplo",level:2},{value:"Notas",id:"notas",level:2},{value:"Mais",id:"mais",level:2}],b={toc:k},v="wrapper";function h(e){let{components:a,...t}=e;return(0,n.kt)(v,(0,o.Z)({},b,t,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"-usando-ferramentas-de-llm"},"\ud83d\udfe1 Usando Ferramentas de LLM"),(0,n.kt)("p",null,"Os sistemas MRKL",(0,n.kt)("sup",{parentName:"p",id:"fnref-1"},(0,n.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," (Racioc\xednio Modular, Conhecimento e Linguagem, ou Modular Reasoning, Knowledge and Language, em ingl\xeas) s\xe3o uma ",(0,n.kt)("strong",{parentName:"p"},"arquitetura neuro-simb\xf3lica")," que combinam LLMs (computa\xe7\xe3o neural) e ferramentas externas como calculadoras (computa\xe7\xe3o simb\xf3lica) para resolver problemas complexos."),(0,n.kt)("p",null,'Um sistema MRKL \xe9 composto por um conjunto de m\xf3dulos (por exemplo, uma calculadora, API de clima, banco de dados, etc.) e um roteador que decide como "rotear" as consultas em linguagem natural para o m\xf3dulo apropriado.'),(0,n.kt)("p",null,"Um exemplo simples de um sistema MRKL \xe9 um LLM que pode usar um aplicativo de calculadora. Este \xe9 um sistema de m\xf3dulo \xfanico, onde o LLM \xe9 o roteador. Quando perguntado, ",(0,n.kt)("inlineCode",{parentName:"p"},"Quanto \xe9 100*100?"),", o LLM pode escolher extrair os n\xfameros da solicita\xe7\xe3o e, em seguida, informar ao sistema MRKL para usar um aplicativo de calculadora para calcular o resultado. Isso pode parecer o seguinte:"),(0,n.kt)("pre",null,(0,n.kt)("p",null,"Quanto \xe9 100*100?"),(0,n.kt)("span",{className:"bluegreen-highlight"},"CALCULADORA[100*100]")),(0,n.kt)("p",null,"O sistema MRKL veria a palavra CALCULADORA e inseriria 100*100 na calculadora.\nEssa ideia simples pode ser facilmente expandida para v\xe1rias ferramentas de computa\xe7\xe3o simb\xf3lica."),(0,n.kt)("p",null,"Considere os seguintes exemplos adicionais de aplicativos:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Um chatbot capaz de responder a perguntas sobre um banco de dados financeiro,\nextraindo informa\xe7\xf5es para formar uma consulta SQL a partir do texto dos usu\xe1rios.")),(0,n.kt)("pre",null,(0,n.kt)("p",null,"Qual o pre\xe7o do stock da Apple nesse exato momento?"),(0,n.kt)("span",{className:"bluegreen-highlight"},'O pre\xe7o do stock da Apple nesse momento \xe9 DATABASE[SELECT price FROM stock WHERE company = "Apple" AND time = "now"].')),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Um chatbot capaz de responder a perguntas sobre o tempo extraindo\ninforma\xe7\xf5es do prompt e usando uma API meteorol\xf3gica para recuperar as informa\xe7\xf5es.")),(0,n.kt)("pre",null,(0,n.kt)("p",null,"Como \xe9 o clima em Nova York?"),(0,n.kt)("span",{className:"bluegreen-highlight"},"O clima \xe9 WEATHER_API[New York].")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Ou at\xe9 realizar tarefas muito mais complexas incluidno v\xe1rios bancos de dados, como nos exemplos a seguir:")),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:r,style:{width:"500px"}})),(0,n.kt)("div",{style:{textAlign:"center"}},"Exemplo de um Systema MRKL (AI21)"),(0,n.kt)("h2",{id:"um-exemplo"},"Um Exemplo"),(0,n.kt)("p",null,"Eu reproduzi um exemplo de Sistema MRKL do artigo original, usando o Dust.tt, dispon\xedvel ",(0,n.kt)("a",{parentName:"p",href:"https://dust.tt/w/f3fa61f0aa/a/17501cd008"},"aqui"),".\nO sistema l\xea um problema matem\xe1tico (por exemplo, ",(0,n.kt)("inlineCode",{parentName:"p"},"Qual \xe9 o resultado de 20 vezes 5^6?"),"), extrai os n\xfameros e as opera\xe7\xf5es,\ne os formata a fim de que possam ser utilizados em  uma calculadora (por exemplo, ",(0,n.kt)("inlineCode",{parentName:"p"},"20*5^6"),"). Em seguida, ele envia a equa\xe7\xe3o reformatada para a calculadora do Google e retorna o resultado. Observe que o artigo original faz um ajuste fino na consulta (no roteador, que \xe9 o LLM), mas eu n\xe3o fa\xe7o isso neste exemplo. Vamos ver como isso funciona:"),(0,n.kt)("p",null,"Primeiro, eu criei um dataset simples na aba ",(0,n.kt)("inlineCode",{parentName:"p"},"Datasets")," do Dust."),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:s,style:{width:"750px"}})),(0,n.kt)("p",null,"Depois, eu mudei para a aba ",(0,n.kt)("inlineCode",{parentName:"p"},"Specification")," e inclui o dataset acima usando um bloco do tipo ",(0,n.kt)("inlineCode",{parentName:"p"},"input"),". "),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:i,style:{width:"750px"}})),(0,n.kt)("p",null,"Em seguida, criei um bloco do tipo ",(0,n.kt)("inlineCode",{parentName:"p"},"lmm")," que extrai os n\xfameros e opera\xe7\xf5es matem\xe1tica. Note que quando eu crio o promt eu passo que estou usando a calculadora do Google. O modelo que eu usei (GPT-3) provavelmente tem algum conhecimento da calculadora do Google devido ao seu pr\xe9-treinamento."),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:l,style:{width:"750px"}})),(0,n.kt)("p",null,"Ent\xe3o eu criei um block do tipo ",(0,n.kt)("inlineCode",{parentName:"p"},"code"),", no qual inclu\xed um c\xf3digo em javascript bem simples para remover os espa\xe7os da resposta."),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:p,style:{width:"750px"}})),(0,n.kt)("p",null,"Finalmente, eu criei um bloco do tipo ",(0,n.kt)("inlineCode",{parentName:"p"},"search")," que manda a equa\xe7\xe3o formatada para a calculadora do Google.\n",(0,n.kt)("strong",{parentName:"p"}," Importante "),': Nessa etapa tive que mandar as instru\xe7\xf5es em ingl\xeas mesmo, j\xe1 que perguntando "Quanto \xe9..." a busca n\xe3o retorna uma calculadora (ou "rich snippet"). '),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:m,style:{width:"750px"}})),(0,n.kt)("p",null,"Abaixo voc\xea pode ver os resultando, que est\xe3o todos corretos!"),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:c,style:{width:"750px"}})),(0,n.kt)("p",null,"Fique \xe0 vontade para copiar e brincar com esse c\xf3digo ",(0,n.kt)("a",{parentName:"p",href:"https://dust.tt/w/f3fa61f0aa/a/17501cd008"},"aqui"),"."),(0,n.kt)("h2",{id:"notas"},"Notas"),(0,n.kt)("p",null,"MRKL foi desenvolvido por ",(0,n.kt)("a",{parentName:"p",href:"https://www.ai21.com/"},"AI21"),", o qual originalmente usaram o LMM\nJ-1 (Jurassic 1)",(0,n.kt)("sup",{parentName:"p",id:"fnref-2"},(0,n.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),"."),(0,n.kt)("h2",{id:"mais"},"Mais"),(0,n.kt)("p",null,"Confira ",(0,n.kt)("a",{parentName:"p",href:"https://python.langchain.com/en/latest/modules/agents/agents/examples/mrkl.html"},"esse exemplo")," de um sistemas MRKL constru\xeddo com LangChain."),(0,n.kt)("div",{className:"footnotes"},(0,n.kt)("hr",{parentName:"div"}),(0,n.kt)("ol",{parentName:"div"},(0,n.kt)("li",{parentName:"ol",id:"fn-1"},"Karpas, E., Abend, O., Belinkov, Y., Lenz, B., Lieber, O., Ratner, N., Shoham, Y., Bata, H., Levine, Y., Leyton-Brown, K., Muhlgay, D., Rozen, N., Schwartz, E., Shachaf, G., Shalev-Shwartz, S., Shashua, A., & Tenenholtz, M. (2022). MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,n.kt)("li",{parentName:"ol",id:"fn-2"},"Lieber, O., Sharir, O., Lentz, B., & Shoham, Y. (2021). Jurassic-1: Technical Details and Evaluation, White paper, AI21 Labs, 2021. URL: Https://Uploads-Ssl. Webflow. Com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_ Tech_paper. Pdf.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")))))}h.isMDXComponent=!0}}]);