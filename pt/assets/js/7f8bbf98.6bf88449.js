"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[1157],{59182:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>c,contentTitle:()=>d,default:()=>g,frontMatter:()=>s,metadata:()=>p,toc:()=>m});var t=o(87462),n=(o(67294),o(3905)),r=o(12554),i=o(39145);const s={sidebar_position:0},d="\ud83d\udfe2 Introduction",p={unversionedId:"prompt_hacking/intro",id:"prompt_hacking/intro",title:"\ud83d\udfe2 Introduction",description:"Hackeamento de prompts \xe9 um termo usado para descrever um tipo de ataque que explora as vulnerabilidades dos %%LLMs|LLM%%, manipulando suas entradas ou prompts. Ao contr\xe1rio do hacking tradicional, que geralmente explora vulnerabilidades de software, o prompt hacking depende da cria\xe7\xe3o cuidadosa de prompts para enganar o LLM a executar a\xe7\xf5es n\xe3o intencionais.",source:"@site/i18n/pt/docusaurus-plugin-content-docs/current/prompt_hacking/intro.md",sourceDirName:"prompt_hacking",slug:"/prompt_hacking/intro",permalink:"/pt/docs/prompt_hacking/intro",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/prompt_hacking/intro.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{sidebar_position:0},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udd13 Prompt Hacking",permalink:"/pt/docs/category/-prompt-hacking"},next:{title:"\ud83d\udfe2 Inje\xe7\xe3o de Prompt",permalink:"/pt/docs/prompt_hacking/injection"}},c={},m=[],u={toc:m},l="wrapper";function g(e){let{components:a,...o}=e;return(0,n.kt)(l,(0,t.Z)({},u,o,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"-introduction"},"\ud83d\udfe2 Introduction"),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:r.Z,style:{width:"30%"}})),(0,n.kt)("p",null,"Hackeamento de prompts \xe9 um termo usado para descrever um tipo de ataque que explora as vulnerabilidades dos ",(0,n.kt)("a",{parentName:"p",id:"LLM_0_109_1689362225523","data-tooltip-html":"Large Language Model. A model that is trained to predict the next word in a sentence.","data-tooltip-place":"top"},"LLMs"),(0,n.kt)(i.u,{anchorId:"LLM_0_109_1689362225523",clickable:!0,mdxType:"Tooltip"}),", manipulando suas entradas ou prompts. Ao contr\xe1rio do hacking tradicional, que geralmente explora vulnerabilidades de software, o prompt hacking depende da cria\xe7\xe3o cuidadosa de prompts para enganar o LLM a executar a\xe7\xf5es n\xe3o intencionais."),(0,n.kt)("p",null,"Nas pr\xf3xima p\xe1ginas abordaremos tr\xeas tipos de prompt hacking: inje\xe7\xe3o de prompt, vazamento de prompt e jailbreaking. A inje\xe7\xe3o de prompt envolve adicionar conte\xfado malicioso ou n\xe3o intencional a um prompt para influenciar a sa\xedda do modelo de linguagem. O vazamento de prompt e o jailbreaking s\xe3o efetivamente subconjuntos disso: o vazamento de prompt envolve a extra\xe7\xe3o de informa\xe7\xf5es sens\xedveis ou confidenciais das respostas do LLM, enquanto o jailbreaking envolve a viola\xe7\xe3o de recursos de seguran\xe7a e modera\xe7\xe3o. Tamb\xe9m discutiremos t\xe9cnicas ofensivas e defensivas espec\xedficas."),(0,n.kt)("p",null,"Para se proteger contra o prompt hacking, medidas defensivas devem ser tomadas. Isso inclui a implementa\xe7\xe3o de defesas baseadas em prompt, a monitoriza\xe7\xe3o regular do comportamento e das sa\xeddas do LLM em busca de atividades incomuns e o uso de ajustes finos ou outras t\xe9cnicas. No geral, o prompt hacking \xe9 uma preocupa\xe7\xe3o crescente para a seguran\xe7a dos LLMs e \xe9 essencial permanecer vigilante e tomar medidas proativas para se proteger contra esses tipos de ataques."))}g.isMDXComponent=!0},12554:(e,a,o)=>{o.d(a,{Z:()=>t});const t=o.p+"assets/images/lock-eefaddf0faef21a0be9b71ae0e7de85d.png"}}]);