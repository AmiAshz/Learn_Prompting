"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[3457],{8323:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>m,contentTitle:()=>l,default:()=>b,frontMatter:()=>s,metadata:()=>d,toc:()=>p});var i=o(7462),t=(o(7294),o(3905));const n=o.p+"assets/images/least_to_most_formal-486e9639afd8c95f3b069b29872d9dfd.webp";var r=o(9145);const s={sidebar_position:7,locale:"es-mx",style:"chicago"},l="\ud83d\udfe1 Least to Most Prompting",d={unversionedId:"intermediate/least_to_most",id:"intermediate/least_to_most",title:"\ud83d\udfe1 Least to Most Prompting",description:"Prompting de menos a m\xe1s (LtM) (Zhou et al., 2022) lleva la t\xe9cnica de %%CoT prompting|prompting de CoT%% un paso m\xe1s all\xe1 al descomponer un problema en subproblemas y resolver cada uno. Esta t\xe9cnica est\xe1 inspirada en estrategias educativas del mundo real para ni\xf1os.",source:"@site/i18n/es/docusaurus-plugin-content-docs/current/intermediate/least_to_most.md",sourceDirName:"intermediate",slug:"/intermediate/least_to_most",permalink:"/es/docs/intermediate/least_to_most",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/intermediate/least_to_most.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7,locale:"es-mx",style:"chicago"},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe1 Generated Knowledge",permalink:"/es/docs/intermediate/generated_knowledge"},next:{title:"\ud83d\udfe2 \xbfQu\xe9 es una Promoci\xf3n?",permalink:"/es/docs/intermediate/whats_in_a_prompt"}},m={},p=[{value:"Ejemplo: Respuesta a una consulta del cliente",id:"ejemplo-respuesta-a-una-consulta-del-cliente",level:2},{value:"Ejemplo: concatenaci\xf3n de letras",id:"ejemplo-concatenaci\xf3n-de-letras",level:2},{value:"Primer intento: Est\xe1ndar",id:"primer-intento-est\xe1ndar",level:3},{value:"Segundo intento: Cadena de pensamiento (CoT)",id:"segundo-intento-cadena-de-pensamiento-cot",level:3},{value:"Tercer intento: De menor a mayor (un solo prompt)",id:"tercer-intento-de-menor-a-mayor-un-solo-prompt",level:3},{value:"Resultados",id:"resultados",level:3},{value:"Ejemplo: generalizaci\xf3n composicional (SCAN)",id:"ejemplo-generalizaci\xf3n-composicional-scan",level:2},{value:"Primer intento: Standard prompting",id:"primer-intento-standard-prompting",level:3},{value:"Segundo intento: De menos a m\xe1s, primer paso - Reducci\xf3n",id:"segundo-intento-de-menos-a-m\xe1s-primer-paso---reducci\xf3n",level:3},{value:"Segundo intento: De menor a mayor, segundo paso - Cartograf\xeda",id:"segundo-intento-de-menor-a-mayor-segundo-paso---cartograf\xeda",level:3},{value:"Resultados",id:"resultados-1",level:3}],c={toc:p},u="wrapper";function b(e){let{components:a,...o}=e;return(0,t.kt)(u,(0,i.Z)({},c,o,{components:a,mdxType:"MDXLayout"}),(0,t.kt)("h1",{id:"-least-to-most-prompting"},"\ud83d\udfe1 Least to Most Prompting"),(0,t.kt)("p",null,"Prompting de menos a m\xe1s (LtM) (Zhou et al., 2022) lleva la t\xe9cnica de ",(0,t.kt)("a",{parentName:"p",id:"prompting de CoT_0_71_1690058691571","data-tooltip-html":"La idea principal de CoT es que al mostrarle al LLM algunos ejemplos de few-shot donde se explica el proceso de razonamiento en los ejemplos, el LLM tambi\xe9n mostrar\xe1 el proceso de razonamiento al responder a la solicitud.","data-tooltip-place":"top"},"CoT prompting"),(0,t.kt)(r.u,{anchorId:"prompting de CoT_0_71_1690058691571",clickable:!0,mdxType:"Tooltip"})," un paso m\xe1s all\xe1 al descomponer un problema en subproblemas y resolver cada uno. Esta t\xe9cnica est\xe1 inspirada en estrategias educativas del mundo real para ni\xf1os."),(0,t.kt)("p",null,"Al igual que en CoT prompting, el problema a resolver se descompone en un conjunto de subproblemas que se construyen uno sobre otro. En una segunda etapa, estos subproblemas se resuelven uno por uno. A diferencia de la cadena de pensamiento, la soluci\xf3n de los subproblemas anteriores se alimenta en el prompt para tratar de resolver el siguiente problema."),(0,t.kt)("div",{style:{textAlign:"center"}},(0,t.kt)("img",{src:n,style:{width:"600px"},alt:"A diagram of a least to most prompting"})),(0,t.kt)("div",{style:{textAlign:"center"}},"Diagram of a Least to Most prompting"),(0,t.kt)("h2",{id:"ejemplo-respuesta-a-una-consulta-del-cliente"},"Ejemplo: Respuesta a una consulta del cliente"),(0,t.kt)("p",null,"Formulemos una pregunta de atenci\xf3n al cliente un poco complicada:"),(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwIn0%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("br",null),"Esto ha fallado (estamos dentro del tiempo de retorno), as\xed que vamos a intentar dividirlo en subproblemas:",(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwIn0%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("br",null),"Tratemos de resolver el primer subproblema:",(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwIn0%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("p",null,"Con s\xf3lo resolver el primer subproblema, pod\xedamos resolver todo el problema. Si GPT-3 no devolv\xeda una respuesta inmediatamente, podr\xedamos haber resuelto el siguiente subproblema y as\xed sucesivamente hasta que devolviera una respuesta. Obs\xe9rvese que utilizamos ",(0,t.kt)("inlineCode",{parentName:"p"},"Vayamos paso a paso"),". La adici\xf3n de esta frase no siempre es necesaria, pero ayuda para este ejemplo."),(0,t.kt)("h2",{id:"ejemplo-concatenaci\xf3n-de-letras"},"Ejemplo: concatenaci\xf3n de letras"),(0,t.kt)("p",null,"LtM se introdujo originalmente utilizando una solicitud de pocos ejemplos, en lugar de una instrucci\xf3n expl\xedcita para descomponer un problema en m\xfaltiples pasos (como se ve arriba). Adem\xe1s, a veces se puede implementar con una sola solicitud en lugar de solicitudes concatenadas. Examinemos el problema de concatenar la \xfaltima letra de palabras individuales",(0,t.kt)("sup",{parentName:"p",id:"fnref-1"},(0,t.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," (por ejemplo, dadas las palabras de entrada cake, etymology, la salida deber\xeda ser ey)."),(0,t.kt)("h3",{id:"primer-intento-est\xe1ndar"},"Primer intento: Est\xe1ndar"),(0,t.kt)("p",null,"El prompt est\xe1ndar con ejemplos de few-shot funciona muy mal, incluso con un modelo m\xe1s avanzado como text-davinci-003."),(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwLjIifQ%3D%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("h3",{id:"segundo-intento-cadena-de-pensamiento-cot"},"Segundo intento: Cadena de pensamiento (CoT)"),(0,t.kt)("p",null,"Chain of Thought obtiene unos resultados significativamente mejores que los de la incitaci\xf3n est\xe1ndar. Esto se debe a que ahora permite al modelo considerar la extracci\xf3n de la \xfaltima letra de cada palabra por s\xed mismo, reduciendo la complejidad a la operaci\xf3n de agrupar letras que ha recogido previamente. Sin embargo, esto empieza a fallar con tama\xf1os m\xe1s grandes."),(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwLjIifQ%3D%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("h3",{id:"tercer-intento-de-menor-a-mayor-un-solo-prompt"},"Tercer intento: De menor a mayor (un solo prompt)"),(0,t.kt)("p",null,"Con el m\xe9todo de menor a mayor, aumentamos el concepto de cadena de pensamiento reformulando los pasos individuales para volver a expresar el resultado concatenado previamente. De este modo, cada paso se reduce a concatenar una sola letra nueva. As\xed se obtienen buenos resultados hasta 12 o m\xe1s palabras."),(0,t.kt)("p",null,'Este enfoque puede parecer muy similar al de la Cadena de Pensamiento, pero es conceptualmente muy diferente. Aqu\xed, en cada paso, introducimos la concatenaci\xf3n anterior. En el caso de "think, machine, learning", en lugar de concatenar las letras "k", "e", "g" individualmente, concatenar\xe1 "k" y "e", luego "ke" y "g". Como resultado de esta reintroducci\xf3n del trabajo anterior, el modelo puede ahora generalizarse a cadenas mucho m\xe1s largas porque lleva el resultado de forma incremental y s\xf3lo necesita hacer una peque\xf1a cantidad de trabajo en cada paso.'),(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwLjIifQ%3D%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("h3",{id:"resultados"},"Resultados"),(0,t.kt)("p",null,"En el \xfaltimo problema de concatenaci\xf3n de letras con 12 palabras, Chain of Thought tiene una precisi\xf3n del 34%, mientras que Least to Most tiene una precisi\xf3n del 74% (el art\xedculo utiliza text-davinci-002 como modelo)."),(0,t.kt)("h2",{id:"ejemplo-generalizaci\xf3n-composicional-scan"},"Ejemplo: generalizaci\xf3n composicional (SCAN)"),(0,t.kt)("p",null,"La prueba de referencia SCAN",(0,t.kt)("sup",{parentName:"p",id:"fnref-2"},(0,t.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),' requiere que el modelo convierta el lenguaje natural en secuencias de acciones. Por ejemplo, la frase "correr a la izquierda y caminar dos veces" se traducir\xeda como " TURN_LEFT + RUN + WALK ',"*",' 2". Los modelos ling\xfc\xedsticos funcionan especialmente mal cuando se enfrentan a secuencias m\xe1s largas que las del conjunto de entrenamiento.'),(0,t.kt)("h3",{id:"primer-intento-standard-prompting"},"Primer intento: Standard prompting"),(0,t.kt)("p",null,"Utilizando prompts est\xe1ndar simples, text-davinci-003 llega impresionantemente lejos, pero sigue fallando."),(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwLjIifQ%3D%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("h3",{id:"segundo-intento-de-menos-a-m\xe1s-primer-paso---reducci\xf3n"},"Segundo intento: De menos a m\xe1s, primer paso - Reducci\xf3n"),(0,t.kt)("p",null,"Aqu\xed, trabajamos con 2 diferentes prompts. El primer prompt se utiliza para reducir el problema de entrada a una secuencia de pasos m\xe1s simple. El segundo prompt se utiliza para mapear esta secuencia simplificada de pasos en acciones reales."),(0,t.kt)("p",null,"Ambos prompts son bastante largos y usan notaci\xf3n de Python comprimida para la acci\xf3n para ahorrar tokens."),(0,t.kt)("p",null,'El primer paso descompone la descripci\xf3n del lenguaje natural en un lenguaje m\xe1s expl\xedcito, pero a\xfan humano. Esto ayudar\xe1 al paso de mapeo a entender las cosas en secuencia.\nPor ejemplo, "saltar hacia la izquierda dos veces" se reduce a "saltar a la izquierda" -> ',(0,t.kt)("inlineCode",{parentName:"p"},"TURN_LEFT + JUMP"),' y "saltar alrededor a la izquierda" -> ',(0,t.kt)("inlineCode",{parentName:"p"},"(TURN_LEFT + JUMP) * 4"),". Del mismo modo, el paso de reducci\xf3n es el que se utiliza para explicar el concepto de repetici\xf3n (dos veces, tres veces, etc...)."),(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwLjIifQ%3D%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("h3",{id:"segundo-intento-de-menor-a-mayor-segundo-paso---cartograf\xeda"},"Segundo intento: De menor a mayor, segundo paso - Cartograf\xeda"),(0,t.kt)("p",null,"En el segundo paso, utilizamos el resultado de la reducci\xf3n y, de nuevo, una instrucci\xf3n bastante larga (14 casos) para traducir la descripci\xf3n reducida en lenguaje natural en una secuencia de acciones."),(0,t.kt)("p",null,"Aqu\xed inyectamos el resultado del primer paso:"),(0,t.kt)("blockquote",null,(0,t.kt)("p",{parentName:"blockquote"},'"saltar dos veces a la izquierda" puede resolverse con: "saltar a la izquierda", "saltar alrededor de la izquierda", "saltar alrededor de la izquierda dos veces". "camina hacia la izquierda tres veces" puede ser resuelto por: "caminar opuesto a la izquierda", "caminar opuesto a la izquierda tres veces". Por lo tanto, "saltar alrededor de la izquierda dos veces despu\xe9s de caminar frente a la izquierda tres veces" se puede resolver por: "saltar a la izquierda", "saltar alrededor de la izquierda", "saltar alrededor de la izquierda dos veces", "caminar opuesto a la izquierda", "caminar opuesto a la izquierda tres veces".')),(0,t.kt)("p",null,"en el LLM."),(0,t.kt)("iframe",{src:"http://embed.learnprompting.org/embed?config=eyJib3hSb3dzIjoyNSwidG9wUCI6MSwidGVtcGVyYXR1cmUiOjAuNywibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IiIsIm1vZGVsIjoiZ3B0LTQiLCJ1bmRlZmluZWQiOiIwLjIifQ%3D%3D",style:{width:"100%",height:"1250px",border:"0",borderRadius:"4px",overflow:"hidden"},sandbox:"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"}),(0,t.kt)("h3",{id:"resultados-1"},"Resultados"),(0,t.kt)("p",null,"LtM conlleva m\xfaltiples mejoras:"),(0,t.kt)("ul",null,(0,t.kt)("li",{parentName:"ul"},"mejora de la precisi\xf3n con respecto a Chain of Thought"),(0,t.kt)("li",{parentName:"ul"},"mayor generalizaci\xf3n en problemas m\xe1s dif\xedciles que los del prompt"),(0,t.kt)("li",{parentName:"ul"},"mejora espectacular del rendimiento en la generalizaci\xf3n composicional, en particular en la prueba de referencia SCAN",(0,t.kt)("sup",{parentName:"li",id:"fnref-2"},(0,t.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),".")),(0,t.kt)("p",null,"Las instrucciones est\xe1ndar con texto-davinci-002 (el modelo utilizado en el art\xedculo) dan como resultado un 6% de problemas SCAN resueltos con \xe9xito, mientras que las instrucciones de menor a mayor dan como resultado una impresionante tasa de \xe9xito del 76%. Los resultados son a\xfan m\xe1s significativos con code-davinci-002, donde Least to Most logra una tasa de \xe9xito del 99.7%."),(0,t.kt)("div",{className:"footnotes"},(0,t.kt)("hr",{parentName:"div"}),(0,t.kt)("ol",{parentName:"div"},(0,t.kt)("li",{parentName:"ol",id:"fn-1"},"Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.\n",(0,t.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,t.kt)("li",{parentName:"ol",id:"fn-2"},"Lake, B. M., & Baroni, M. (2018). Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks. https://doi.org/10.48550/arXiv.1711.00350\n",(0,t.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")))))}b.isMDXComponent=!0}}]);